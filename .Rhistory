)
return(output)
} %>% drop_na()
judgments_annotated_parts = foreach(i = seq(judgments_annotated$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotated$annotations[[i]]), .combine = "rbind") %do% {
text_length = str_length(judgments_annotated$text[[i]])
output = tibble(
"doc_id" = judgments_annotated$doc_id[i],
"text" = judgments_annotated$annotations[[i]][j,4],
"class" = judgments_annotated$annotations[[i]][j,2],
"start" = judgments_annotated$annotations[[i]][j,3]/text_length,
"end" = judgments_annotated$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotated$annotations[[i]][j,4])/text_length
)
return(output)
}
judgments_annotated_parts = foreach(i = seq(judgments_annotated$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotated$annotations[[i]]), .combine = "rbind") %do% {
text_length = str_length(judgments_annotated$text[[i]])
output = tibble(
"doc_id" = judgments_annotated$doc_id[i],
"text" = judgments_annotated$annotations[[i]][j,4],
"class" = judgments_annotated$annotations[[i]][j,2],
"start" = judgments_annotated$annotations[[i]][j,3]/text_length,
"end" = judgments_annotated$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotated$annotations[[i]][j,4])/text_length
)
return(output)
} %>% drop_na()
judgments_annotated_paragraphs = foreach(i = seq(nrow(judgments_annotated_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
judgments_annotated_paragraphs_temp = judgments_annotated_parts$text[i] %>% str_split(pattern = "\n\n")
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[[1]] %>% as.vector()
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[! judgments_annotated_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp = judgments_annotated$text[judgments_annotated$doc_id == judgments_annotated_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output = foreach(j = seq(judgments_annotated_paragraphs_temp), .combine = "rbind") %do% {
location_temp = str_locate(string = text_temp, pattern = fixed(judgments_annotated_paragraphs_temp[j])) %>% as.list()
text_length = str_length(text_temp)
output = tibble(
"doc_id" = judgments_annotated_parts$doc_id[i],
"text" = judgments_annotated_paragraphs_temp[j],
"class" = judgments_annotated_parts$class[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(judgments_annotated_paragraphs_temp[j])/text_length
)
return(output)
}
} %>% mutate(
doc_id = doc_id %>%
make.unique()
)
judgments_annotated_parts$class
judgments_annotated_paragraphs = foreach(i = seq(nrow(judgments_annotated_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
judgments_annotated_paragraphs_temp = judgments_annotated_parts$text[i] %>% str_split(pattern = "\n\n")
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[[1]] %>% as.vector()
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[! judgments_annotated_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp = judgments_annotated$text[judgments_annotated$doc_id == judgments_annotated_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output = foreach(j = seq(judgments_annotated_paragraphs_temp), .combine = "rbind") %do% {
location_temp = str_locate(string = text_temp, pattern = fixed(judgments_annotated_paragraphs_temp[j])) %>% as.list()
text_length = str_length(text_temp)
output = tibble(
"doc_id" = judgments_annotated_parts$doc_id[i],
"text" = judgments_annotated_paragraphs_temp[j],
"class" = judgments_annotated_parts$class[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(judgments_annotated_paragraphs_temp[j])/text_length
)
return(output)
}
} %>% mutate(
doc_id = doc_id %>%
make.unique()
)
xfun::pkg_attach2("tidyverse", "ggplot2", "progress", "foreach", "jsonlite",  "word2vec", "udpipe")
judgments_annotated1 = jsonlite::fromJSON(txt = "../data/us_partitioning_sample1.json")
judgments_annotated2 = jsonlite::fromJSON(txt = "../data/us_partitioning_sample2.json")
judgments_annotated1 = judgments_annotated1$examples %>% as_tibble()
judgments_annotated2 = judgments_annotated2$examples %>% as_tibble()
judgments_annotated = bind_rows(judgments_annotated1, judgments_annotated2) %>%
rename("text" = "content") %>%
mutate(doc_id = metadata$doc_id) %>%
select(-metadata)
remove(judgments_annotated1, judgments_annotated2)
judgments_annotated_parts = foreach(i = seq(judgments_annotated$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotated$annotations[[i]]), .combine = "rbind") %do% {
text_length = str_length(judgments_annotated$text[[i]])
output = tibble(
"doc_id" = judgments_annotated$doc_id[i],
"text" = judgments_annotated$annotations[[i]][j,4],
"class" = judgments_annotated$annotations[[i]][j,2],
"start" = judgments_annotated$annotations[[i]][j,3]/text_length,
"end" = judgments_annotated$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotated$annotations[[i]][j,4])/text_length
)
return(output)
} %>% drop_na()
judgments_annotated_paragraphs = foreach(i = seq(nrow(judgments_annotated_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
judgments_annotated_paragraphs_temp = judgments_annotated_parts$text[i] %>% str_split(pattern = "\n\n")
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[[1]] %>% as.vector()
judgments_annotated_paragraphs_temp = judgments_annotated_paragraphs_temp[! judgments_annotated_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp = judgments_annotated$text[judgments_annotated$doc_id == judgments_annotated_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output = foreach(j = seq(judgments_annotated_paragraphs_temp), .combine = "rbind") %do% {
location_temp = str_locate(string = text_temp, pattern = fixed(judgments_annotated_paragraphs_temp[j])) %>% as.list()
text_length = str_length(text_temp)
output = tibble(
"doc_id" = judgments_annotated_parts$doc_id[i],
"text" = judgments_annotated_paragraphs_temp[j],
"class" = judgments_annotated_parts$class[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(judgments_annotated_paragraphs_temp[j])/text_length
)
return(output)
}
} %>% mutate(
doc_id = doc_id %>%
make.unique()
)
# Clear up the environment
remove(judgments_annotated, judgments_annotated_parts)
ud_model = udpipe_load_model(file = "../apex_courts_dataset/czech-pdt-ud-2.5-191206.udpipe")
n.cores = parallel::detectCores() - 1
# lemmatize the text
judgments_annotated_paragraphs %<>%
select(doc_id, text) %>%
udpipe(x = ., object = ud_model, parallel.cores = n.cores) %>%
as_tibble() %>%
select(doc_id, paragraph_id, start, end, lemma, upos) %>%
udpipe_into_lemma(paragraphs = FALSE) %>%
left_join(judgments_annotated_paragraphs %>%
select(-text), .)
# Transform the UDPipe model into a paragraph-level lemmatized text with ID information as well as information on length and position of the paragraphs
udpipe_into_lemma = function(data, paragraphs = TRUE){
if(paragraphs){
output = data %>%
group_by(doc_id, paragraph_id) %>%
filter(str_length(lemma) >= 3) %>%
filter(
!str_detect(lemma, "[0-9]")
) %>%
filter(upos != "PUNCT") %>%
summarise(text = paste(lemma, collapse = " ") %>% # Normalise and tidy the text
str_to_lower() %>%
str_squish(),
start = min(start, na.rm = TRUE),
end = max(end, na.rm = TRUE),
length = end - start) %>%
ungroup() %>%
group_by(doc_id) %>%
mutate(
length = length/max(end),
start = start/max(end),
end = end/max(end)
)
return(output)
}
else{
output = data %>%
group_by(doc_id) %>%
filter(str_length(lemma) >= 3) %>%
filter(
!str_detect(lemma, "[0-9]")
) %>%
filter(upos != "PUNCT") %>%
summarise(text = paste(lemma, collapse = " ") %>% # Normalise and tidy the text
str_to_lower() %>%
str_squish())
return(output)
}
}
# lemmatize the text
judgments_annotated_paragraphs %<>%
select(doc_id, text) %>%
udpipe(x = ., object = ud_model, parallel.cores = n.cores) %>%
as_tibble() %>%
select(doc_id, paragraph_id, start, end, lemma, upos) %>%
udpipe_into_lemma(paragraphs = FALSE) %>%
left_join(judgments_annotated_paragraphs %>%
select(-text), .)
# Load the word2vec model for doc2vec use
word2vec_model = read.word2vec(file = "models/word2vec_model_skipgram.bin")
# Create doc2vec model
judgments_annotated_doc2vec = judgments_annotated_paragraphs %>%
select(doc_id, text) %>%
doc2vec(word2vec_model, newdata = ., type = "embedding") %>%
as.data.frame() %>% # Tibble throws error when working with rownames
rownames_to_column(var = "doc_id") %>%
drop_na() %>%
left_join(., judgments_annotated_paragraphs %>%
select(-text)) %>%
mutate(doc_id = doc_id %>% str_remove(pattern = "\\.\\d+"),
class = factor(class)) %>%
modify(.f = unlist) %>%
as_tibble()
# Save the file
saveRDS(judgments_annotated_doc2vec, file = "../data/judgments_annotated_doc2vec.rds")
data = readRDS("../data/judgments_annotated_doc2vec.rds")
# Data prep depending on the goal
# Create a binary variable for the presence of dissent in the decision, and include only the information on dissents
filter_dissenting_decisions = function(data, metadata = readRDS("../data/US_metadata.rds"), remove_dissent){
if(remove_dissent){
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = if_else(dissenting_opinion == "", 0, 1)) %>%
filter(dissenting_opinion == 1) %>%
mutate(class = case_when(
class != "dissent" ~ "not_dissent",
.default = "dissent"
)) %>%
select(-dissenting_opinion) %>%
mutate(class = factor(class))
return(output)
}
else{
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = case_when(dissenting_opinion != "" ~ 1,
.default = 0)) %>%
filter(dissenting_opinion == 0) %>%
select(-dissenting_opinion) %>%
mutate(class = case_when(
class == "comments" ~ "procedure history",
.default = class
)) %>%
filter(class != "costs") %>%
mutate(class = factor(class))
return(output)
}
}
data = filter_dissenting_decisions(data = judgments_annotated_doc2vec, remove_dissent = FALSE)
data = readRDS("../data/judgments_annotated_doc2vec.rds")
data = filter_dissenting_decisions(data = judgments_annotated_doc2vec, remove_dissent = TRUE)
balanced = oversample(dataset = data, method = "SMOTE", ratio = 0.5)
skim(data)
xfun::pkg_attach2("tidyverse", "tidymodels", "themis", "xgboost", "doParallel", "parallel", "iterators", "skimr")
skim(data)
xfun::pkg_attach2("tidyverse", "tidymodels", "themis", "xgboost", "doParallel", "parallel", "iterators", "skimr")
data = readRDS("../data/data.rds")
data = readRDS("../data/judgments_annotated_doc2vec.rds")
# Data prep depending on the goal
# Create a binary variable for the presence of dissent in the decision, and include only the information on dissents
filter_dissenting_decisions = function(data, metadata = readRDS("../data/US_metadata.rds"), remove_dissent){
if(remove_dissent){
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = if_else(dissenting_opinion == "", 0, 1)) %>%
filter(dissenting_opinion == 1) %>%
mutate(class = case_when(
class != "dissent" ~ "not_dissent",
.default = "dissent"
)) %>%
select(-dissenting_opinion) %>%
mutate(class = factor(class))
return(output)
}
else{
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = case_when(dissenting_opinion != "" ~ 1,
.default = 0)) %>%
filter(dissenting_opinion == 0) %>%
select(-dissenting_opinion) %>%
mutate(class = case_when(
class == "comments" ~ "procedure history",
.default = class
)) %>%
filter(class != "costs") %>%
mutate(class = factor(class))
return(output)
}
}
data = filter_dissenting_decisions(data = data, remove_dissent = TRUE)
set.seed(222)
# Put 3/4 of the data into the training set
data_split = initial_split(data, prop = 3/4)
# Create data frames for the two sets:
train_data = training(data_split)
test_data  = testing(data_split)
svm_rec = recipe(class ~ ., data = train_data) %>%
update_role(all_double(), new_role = "predictor") %>%
update_role(doc_id, new_role = "ID") %>%
update_role(class, new_role = "outcome") %>%
themis::step_smote(class)
svm_rec
# This creates a model object, in which you set the model specifications including the parameters with the tuned values or the engine of the model
svm_mod = svm_linear(cost = 0.01) %>%
set_engine("LiblineaR") %>%
set_mode("classification")
svm_mod
# Bind the model and the recipe to a workflow
svm_wflow = workflow() %>%
add_model(svm_mod) %>%
add_recipe(svm_rec)
# Instead of training on the whole train data, let's do cross validation
folds = vfold_cv(train_data, v = 6)
# This does a basic cross validation
svm_fit_cv = svm_wflow %>%
fit_resamples(folds)
collect_metrics(svm_fit_cv)
svm_rec = recipe(class ~ ., data = train_data) %>%
update_role(all_double(), new_role = "predictor") %>%
update_role(doc_id, new_role = "ID") %>%
update_role(class, new_role = "outcome") %>%
themis::step_smote(class)
svm_rec
View(data)
svm_mod = svm_linear(cost = 0.01) %>%
set_engine("LiblineaR") %>%
set_mode("classification")
svm_mod
svm_wflow = workflow() %>%
add_model(svm_mod) %>%
add_recipe(svm_rec)
# Instead of training on the whole train data, let's do cross validation
folds = vfold_cv(train_data, v = 6)
# This does a basic cross validation
svm_fit_cv = svm_wflow %>%
fit_resamples(folds)
svm_fit = svm_wflow %>%
fit(data = train_data)
svm_aug =
augment(svm_fit, test_data) %>%
select(doc_id, class, .pred_class)
svm_aug %>%
accuracy(truth = class, .pred_class)
svm_aug %>%
conf_mat(truth = class, .pred_class)
xfun::pkg_attach2("tidyverse", "tidymodels", "themis", "xgboost", "doParallel", "parallel", "LiblineaR", "skimr")
data = readRDS("../data/judgments_annotated_doc2vec.rds")
# Data prep depending on the goal
# Create a binary variable for the presence of dissent in the decision, and include only the information on dissents
filter_dissenting_decisions = function(data, metadata = readRDS("../data/US_metadata.rds"), remove_dissent){
if(remove_dissent){
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = if_else(dissenting_opinion == "", 0, 1)) %>%
filter(dissenting_opinion == 1) %>%
mutate(class = case_when(
class != "dissent" ~ "not_dissent",
.default = "dissent"
)) %>%
select(-dissenting_opinion) %>%
mutate(class = factor(class))
return(output)
}
else{
output = metadata %>%
select(doc_id, dissenting_opinion) %>%
left_join(data, ., by = "doc_id") %>%
mutate(dissenting_opinion = case_when(dissenting_opinion != "" ~ 1,
.default = 0)) %>%
filter(dissenting_opinion == 0) %>%
select(-dissenting_opinion) %>%
mutate(class = case_when(
class == "comments" ~ "procedure history",
.default = class
)) %>%
filter(class != "costs") %>%
mutate(class = factor(class))
return(output)
}
}
data = filter_dissenting_decisions(data = data, remove_dissent = TRUE)
set.seed(222)
# Put 3/4 of the data into the training set
data_split = initial_split(data, prop = 3/4)
# Create data frames for the two sets:
train_data = training(data_split)
test_data  = testing(data_split)
# Instead of training on the whole train data, let's do cross validation
folds = vfold_cv(train_data, v = 6)
# Tuning
# This creates a recipe object. A recipe object contains the formula for the model as well as additional information for example on the role of the columns in a dataframe (ID, predictor, outcome)
svm_rec = recipe(class ~ ., data = train_data) %>%
update_role(all_double(), new_role = "predictor") %>%
update_role(doc_id, new_role = "ID") %>%
update_role(class, new_role = "outcome") %>%
step_smote(class)
svm_rec
# This creates a model object, in which you set the model specifications including the parameters to be tuned or the engine of the model
svm_mod = svm_linear(cost = tune()) %>%
set_engine("kernlab") %>%
set_mode("classification")
svm_mod
# Bind the model and the recipe to a workflow
svm_wflow = workflow() %>%
add_model(svm_mod) %>%
add_recipe(svm_rec)
# Firstly we create a grid with the tuning parameters
svm_tune = grid_regular(cost(), levels = 5)
# We then tune the model with the tune_grid() function
svm_tune = svm_wflow %>%
tune_grid(resamples = folds, grid = svm_tune)
svm_fit_final = svm_wflow_final %>%
fit(data)
# Now we input the best parameters into the final workflow with the finalize_workflow() function
svm_wflow_final =
svm_wflow %>%
finalize_workflow(best_cost)
svm_tune %>% collect_metrics()
svm_tune %>% show_best("accuracy")
best_cost = svm_tune %>% select_best("accuracy")
# Now we input the best parameters into the final workflow with the finalize_workflow() function
svm_wflow_final =
svm_wflow %>%
finalize_workflow(best_cost)
svm_fit_final = svm_wflow_final %>%
fit(data)
svm_fit_final %>% collect_metrics()
svm_fit_final %>%
collect_predictions() %>%
roc_curve(class, .pred_dissent) %>%
autoplot()
# Lastly, the model is both trained and then fitted to the testing data with the last_fit() function; this function fits the finalized model on the full training data set and evaluates the finalized model on the testing data.
svm_fit_final = svm_wflow_final %>%
last_fit(data_split)
svm_fit_final %>% collect_metrics()
svm_fit_final %>%
collect_predictions() %>%
roc_curve(class, .pred_dissent) %>%
autoplot()
svm_fit_final = svm_wflow_final %>%
fit(train_data)
# Measuring the accuracy of the basic model with the augment function or predict, which requires further specifications and more actions
svm_aug =
augment(svm_fit_final, test_data) %>%
select(doc_id, class, .pred_class)
svm_aug %>%
accuracy(truth = class, .pred_class)
svm_aug %>%
conf_mat(truth = class, .pred_class)
# Testing the model fit on test data
predict(svm_fit, test_data)
save.image(file = "../data/tuned_model_data.RData")
xgboost_rec = recipe(class ~ ., data = train_data) %>%
update_role(all_double(), new_role = "predictor") %>%
update_role(doc_id, new_role = "ID") %>%
update_role(class, new_role = "outcome") %>%
step_smote(class)
xgboost_rec
xgboost_mod = boost_tree(
trees = 1000,
tree_depth = tune(), min_n = tune(),
loss_reduction = tune(),
sample_size = tune(), mtry = tune(),
learn_rate = tune()
) %>%
set_engine("xgboost") %>%
set_mode("classification")
xgboost_mod
xgboost_grid = grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
finalize(mtry(), train_data),
learn_rate(),
size = 30
)
xgboost_wflow = workflow() %>%
add_model(xgboost_mod) %>%
add_recipe(xgboost_rec)
# Parallelize the process of tuning
doParallel::registerDoParallel()
xgboost_res = tune_grid(
xgboost_wflow,
resamples = folds,
grid = xgboost_grid,
control = control_grid(save_pred = TRUE)
)
# What are the most important parameters for variable importance?
final_xgboost_wflow %>%
fit(data = train_data) %>%
extract_fit_parsnip() %>%
vip::vip(geom = "point")
# Select the best parameters for the final tuning
best_auc = select_best(xgboost_res, "roc_auc")
# Finalize the model workflow with inputting the tuned parameters to the workflow
final_xgboost_wflow = finalize_workflow(
xgboost_wflow,
best_auc
)
# The final fit using the finalized wflow from previous lines
final_xgboost_fit = final_xgboost_wflow %>%
last_fit(data_split)
preds = final_xgboost_fit %>% collect_predictions()
final_xgboost_fit %>% collect_metrics()
# What are the most important parameters for variable importance?
final_xgboost_wflow %>%
fit(data = train_data) %>%
extract_fit_parsnip() %>%
vip::vip(geom = "point")
save.image(file = "../data/tuned_model_data.RData")
setwd("~/Library/CloudStorage/OneDrive-Humboldt-UniversitaetzuBerlin,CMS/Programming/courses/courts_workshop")
### alternative models ###
load("train_test_ml.RData")
View(train_data)
