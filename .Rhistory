"tag" = judgments_annotations$annotations[[i]][j,2],
"start" = judgments_annotations$annotations[[i]][j,3]/text_length,
"end" = judgments_annotations$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotations$annotations[[i]][j,4])/text_length
)
return(output)
} %>% as_tibble() %>% df_unlist() %>% drop_na()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
View(data_parts)
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
xfun::pkg_attach2("tidyverse", "ggplot2", "progress", "foreach", "jsonlite",  "word2vec", "e1071", "caret", "tidymodels", "skimr")
#Load data
source("supporting_functions.R")
#Load data
source("supporting_functions.R")
xfun::pkg_attach2("tidyverse", "ggplot2", "progress", "foreach", "jsonlite",  "word2vec", "e1071", "caret", "tidymodels", "skimr")
#Load data
source("supporting_functions.R")
judgments_annotated <- jsonlite::fromJSON(txt = "data/US_judgments_annotated.json")
judgments_annotations <- judgments_annotated$examples %>% as.data.frame()
data_parts <- foreach(i = seq(judgments_annotations$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotations$annotations[[i]]), .combine = "rbind") %do% {
text_length <- str_length(judgments_annotations$content[[i]])
output <- list(
"doc_id" = judgments_annotations$metadata$doc_id[i],
"value" = judgments_annotations$annotations[[i]][j,4],
"tag" = judgments_annotations$annotations[[i]][j,2],
"start" = judgments_annotations$annotations[[i]][j,3]/text_length,
"end" = judgments_annotations$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotations$annotations[[i]][j,4])/text_length
)
return(output)
} %>% as_tibble() %>% df_unlist() %>% drop_na()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
View(data_parts)
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
browse()
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
browser()
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
browser()
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
?nrow
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[!data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
xfun::pkg_attach2("tidyverse", "ggplot2", "progress", "foreach", "jsonlite",  "word2vec", "e1071", "caret")
#Load data
source("supporting_functions.R")
# Load annotated data and create it into tibble of tag-level observations
judgments_annotated <- jsonlite::fromJSON(txt = "data/US_judgments_annotated.json")
judgments_annotations <- judgments_annotated$examples %>% as.data.frame()
data_parts <- foreach(i = seq(judgments_annotations$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotations$annotations[[i]]), .combine = "rbind") %do% {
text_length <- str_length(judgments_annotations$content[[i]])
output <- list(
"doc_id" = judgments_annotations$metadata$doc_id[i],
"value" = judgments_annotations$annotations[[i]][j,4],
"tag" = judgments_annotations$annotations[[i]][j,2],
"start" = judgments_annotations$annotations[[i]][j,3]/text_length,
"end" = judgments_annotations$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotations$annotations[[i]][j,4])/text_length
)
return(output)
} %>% as_tibble() %>% df_unlist() %>% drop_na()
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
} %>% df_unlist()
View(data_paragraphs)
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble()
}
data_paragraphs
?modify
data_paragraphs <- data_paragraphs %>% modify (.f = unlist)
data_paragraphs
?modify_if
unlist2 <- function(data) {
data <- data %>% modify(.f = unlist)
return(data)
}
data_paragraphs <- foreach(i = seq(nrow(data_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
data_paragraphs_temp <- data_parts$value[i] %>% str_split(pattern = "\n\n")
data_paragraphs_temp <- data_paragraphs_temp[[1]] %>% as.vector()
data_paragraphs_temp <- data_paragraphs_temp[! data_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == data_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(data_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(data_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = data_parts$doc_id[i],
"value" = data_paragraphs_temp[j],
"tag" = data_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(data_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble() %>% unlist2() %>% return()
}
# Load the word2vec model for doc2vec use
word2vec_model_CBOW <- read.word2vec(file = "models/word2vec_model_CBOW.bin")
judgments_annotations_paragraphs$doc_id <- judgments_annotations_paragraphs$doc_id %>% make.unique()
judgments_annotations_parts <- foreach(i = seq(judgments_annotations$annotations), .combine = "rbind") %:%
foreach (j = seq(judgments_annotations$annotations[[i]]), .combine = "rbind") %do% {
text_length <- str_length(judgments_annotations$content[[i]])
output <- list(
"doc_id" = judgments_annotations$metadata$doc_id[i],
"value" = judgments_annotations$annotations[[i]][j,4],
"tag" = judgments_annotations$annotations[[i]][j,2],
"start" = judgments_annotations$annotations[[i]][j,3]/text_length,
"end" = judgments_annotations$annotations[[i]][j,1]/text_length,
"length" = str_length(judgments_annotations$annotations[[i]][j,4])/text_length
)
return(output)
} %>% as_tibble() %>% unlist2() %>% drop_na()
judgments_annotations_paragraphs <- foreach(i = seq(nrow(judgments_annotations_parts)), .combine = "rbind") %do% {
# Create the temporary vector of paragraph texts
judgments_annotations_paragraphs_temp <- judgments_annotations_parts$value[i] %>% str_split(pattern = "\n\n")
judgments_annotations_paragraphs_temp <- judgments_annotations_paragraphs_temp[[1]] %>% as.vector()
judgments_annotations_paragraphs_temp <- judgments_annotations_paragraphs_temp[! judgments_annotations_paragraphs_temp %in% c("")]
#Save the whole judgment text
text_temp <- judgments_annotations$content[judgments_annotations$metadata$doc_id == judgments_annotations_parts$doc_id[i]]
# Split the original parts tibble into paragraph level observations
output <- foreach(j = seq(judgments_annotations_paragraphs_temp), .combine = "rbind") %do% {
location_temp <- str_locate(string = text_temp, pattern = fixed(judgments_annotations_paragraphs_temp[j])) %>% as.list()
text_length <- str_length(text_temp)
output <- list(
"doc_id" = judgments_annotations_parts$doc_id[i],
"value" = judgments_annotations_paragraphs_temp[j],
"tag" = judgments_annotations_parts$tag[i],
"start" = as.numeric(location_temp[1])/text_length,
"end" = as.numeric(location_temp[2])/text_length,
"length" = str_length(judgments_annotations_paragraphs_temp[j])/text_length
)
return(output)
} %>% as_tibble() %>% unlist2() %>% return()
}
# Load the word2vec model for doc2vec use
word2vec_model_CBOW <- read.word2vec(file = "models/word2vec_model_CBOW.bin")
judgments_annotations_paragraphs$doc_id <- judgments_annotations_paragraphs$doc_id %>% make.unique()
# Create doc2vec model
doc2vec_model <- judgments_annotations_paragraphs %>%
select(doc_id, value) %>%
rename(text = value) %>%
doc2vec(word2vec_model_skipgram, newdata = ., type = "embedding") %>%
as.data.frame()
# Load the word2vec model for doc2vec use
word2vec_model_skipgram <- read.word2vec(file = "models/word2vec_model_skipgram.bin")
# Load the word2vec model for doc2vec use
word2vec_model_skipgram <- read.word2vec(file = "models/word2vec_model_skipgram.bin")
